{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Integrity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import ipytest\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PyTest in a Jupyter Notebook\n",
    "Pytest is designed to run tests in .py files which can cause issues when you want to test in a notebook. Normally, this is a good thing, however, in the edge case we are working in, we want to be using a notebook. \n",
    "To do this we are using the ipytest package. After importing the module we are going quickly set it up to test using the autoconfig method, however, we are going to manually set the additional options to ensure that the output is colourful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipytest.autoconfig(addopts=[\"--color=yes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to run pytest using ipytest. The first is with a ipython magic %%ipytest that first executes the cell, then runs the tests found in the cell. It cleans any previously found tests so they don't (re)run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jowi60/TDD_lunch_and_learn, configfile: pytest.ini\n",
      "collected 2 items\n",
      "\n",
      "tmpvdnyx0__.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                            [100%]\u001b[0m\n",
      "\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m____________________________________________ test_fail _____________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_fail\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[94mFalse\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/tmp/ipykernel_333/3225759524.py\u001b[0m:5: AssertionError\n",
      "===================================== short test summary info ======================================\n",
      "FAILED tmpvdnyx0__.py::test_fail - assert False\n",
      "\u001b[31m=================================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.03s\u001b[0m\u001b[31m ====================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_test():\n",
    "    assert True\n",
    "\n",
    "def test_fail():\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to run pytest is to with ipytest.run(). This runs any previously found tests that haven't been cleaned away. It is not advisable to mix and match the two methods as it will result in unexpected behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jowi60/TDD_lunch_and_learn, configfile: pytest.ini\n",
      "collected 2 items\n",
      "\n",
      "tmpxpaqvabc.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                            [100%]\u001b[0m\n",
      "\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m____________________________________________ test_fail _____________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_fail\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[94mFalse\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/tmp/ipykernel_333/3225759524.py\u001b[0m:5: AssertionError\n",
      "===================================== short test summary info ======================================\n",
      "FAILED tmpxpaqvabc.py::test_fail - assert False\n",
      "\u001b[31m=================================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.03s\u001b[0m\u001b[31m ====================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataframes\n",
    "\n",
    "We are going to test this dummy dataset of gp appointment figures. We are expecting the dataset to fit several characteristics which we will test for. The columns we expect in the dataset are:\n",
    "* practice_name: [str] Must be one of Northern Wellness, East End Doctors, West Park Practice, and Southern Health. There is an invalid practice_name included \n",
    "* practice_post_code: [str] Must be a postcode of a valid format. One practice is missing the second letter of the unit postcode.\n",
    "* date: [datetime] Must unique for each practice. East End Doctors has two entries for the same date.\n",
    "* number_of_appointments: [int] Must be positive. Southern Health has a negative value. All values are the wrong datatype.\n",
    "* evil: [bool] Must be true or false and is required (no null values). West Park Practice is missing the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_appointments_dict = [\n",
    "    {\n",
    "        \"practice_name\": \"Northern Wellness\",\n",
    "        \"practice_post_code\": \"NW01 1AB\",\n",
    "        \"date\": datetime(2022,1,1),\n",
    "        \"number_of_appointments\": \"900\",\n",
    "        \"evil\": False\n",
    "    },\n",
    "    {\n",
    "        \"practice_name\": \"Northern Wellness\",\n",
    "        \"practice_post_code\": \"NW01 1AB\",\n",
    "        \"date\": datetime(2022,1,2),\n",
    "        \"number_of_appointments\": \"1000\",\n",
    "        \"evil\": False\n",
    "    },\n",
    "    {\n",
    "        \"practice_name\": \"East End Doctors\",\n",
    "        \"practice_post_code\": \"EE02 2AB\",\n",
    "        \"date\": datetime(2022,1,1),\n",
    "        \"number_of_appointments\": \"100\",\n",
    "        \"evil\": False\n",
    "    },\n",
    "    {\n",
    "        \"practice_name\": \"East End Doctors\",\n",
    "        \"practice_post_code\": \"EE02 2AB\",\n",
    "        \"date\": datetime(2022,1,1),\n",
    "        \"number_of_appointments\": \"100\",\n",
    "        \"evil\": False\n",
    "    },\n",
    "    {\n",
    "        \"practice_name\": \"West Park Practice\",\n",
    "        \"practice_post_code\": \"WP01 1A\",\n",
    "        \"date\": datetime(2022,1,1),\n",
    "        \"number_of_appointments\": \"100000\"\n",
    "    },\n",
    "    {\n",
    "        \"practice_name\": \"Southern Health\",\n",
    "        \"practice_post_code\": \"S01 1AB\",\n",
    "        \"date\": datetime(2022,1,1),\n",
    "        \"number_of_appointments\": \"-100\",\n",
    "        \"evil\": False\n",
    "    },\n",
    "    {\n",
    "        \"practice_name\": \"Snake Oil Cures\",\n",
    "        \"practice_post_code\": \"B01 1AD\",\n",
    "        \"date\": datetime(2022,1,1),\n",
    "        \"number_of_appointments\": \"1000000\",\n",
    "        \"evil\": True\n",
    "    },\n",
    "]\n",
    "\n",
    "df_gp_appointments = pd.DataFrame(gp_appointments_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the schema of the dataframe is correct\n",
    "We can easily compare the dataframe schema against our expected schema by extracting the datatypes fo the columns and converting them to a dictionary. The datatypes will be numpy datatypes, so will look a bit weird but we can lookup online what we should expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jowi60/TDD_lunch_and_learn, configfile: pytest.ini\n",
      "collected 1 item\n",
      "\n",
      "tmpp5iudaf8.py \u001b[31mF\u001b[0m\u001b[31m                                                                             [100%]\u001b[0m\n",
      "\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m___________________________________________ test_columns ___________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_columns\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m expected_schema == df_gp_appointments.dtypes.to_dict()\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert {'date': dtyp...ype('O'), ...} == {'date': dtyp...ype('O'), ...}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Omitting 3 identical items, use -vv to show\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Differing items:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         {'evil': dtype('bool')} != {'evil': dtype('O')}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         {'number_of_appointments': dtype('float64')} != {'number_of_appointments': dtype('O')}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Use -v to get more diff\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/tmp/ipykernel_333/1692329378.py\u001b[0m:10: AssertionError\n",
      "===================================== short test summary info ======================================\n",
      "FAILED tmpp5iudaf8.py::test_columns - AssertionError: assert {'date': dtyp...ype('O'), ...} == {'...\n",
      "\u001b[31m======================================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.03s\u001b[0m\u001b[31m =========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "expected_schema = {\n",
    "        \"practice_name\": np.dtype('O'),\n",
    "        \"practice_post_code\": np.dtype('O'),\n",
    "        \"date\": np.dtype('datetime64[ns]'),\n",
    "        \"number_of_appointments\": np.dtype('float_'),\n",
    "        \"evil\": np.dtype('bool')\n",
    "    }\n",
    "\n",
    "def test_columns():\n",
    "    assert expected_schema == df_gp_appointments.dtypes.to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some failures in how the different datatypes were cast when creating the dateframe, however, with some type conversions we can correct these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jowi60/TDD_lunch_and_learn, configfile: pytest.ini\n",
      "collected 1 item\n",
      "\n",
      "tmpmy3om3vy.py \u001b[32m.\u001b[0m\u001b[32m                                                                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "df_gp_appointments.evil = df_gp_appointments.\\\n",
    "    evil.astype(bool)\n",
    "\n",
    "df_gp_appointments.number_of_appointments = df_gp_appointments.\\\n",
    "    number_of_appointments.\\\n",
    "    astype(np.float64)\n",
    "\n",
    "\n",
    "def test_columns():\n",
    "    assert expected_schema == df_gp_appointments.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jowi60/TDD_lunch_and_learn, configfile: pytest.ini\n",
      "collected 1 item\n",
      "\n",
      "tmpvh5515t8.py \u001b[32m.\u001b[0m\u001b[32m                                                                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "expected_dims = (7,5)\n",
    "\n",
    "def test_dimensions():\n",
    "    assert df_gp_appointments.shape == expected_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the practice names are valid.\n",
    "We can use parametrisation to check all practice names in the dataframe to ensure they are all valid. Snake Oil Cures is invalid and has been flagged as failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jowi60/TDD_lunch_and_learn, configfile: pytest.ini\n",
      "collected 5 items\n",
      "\n",
      "tmpwfewm67j.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                         [100%]\u001b[0m\n",
      "\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m_______________________________ test_practice_names[Snake Oil Cures] _______________________________\u001b[0m\n",
      "\n",
      "practice_name = 'Snake Oil Cures'\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mpractice_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, df_gp_appointments[\u001b[33m\"\u001b[39;49;00m\u001b[33mpractice_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].unique())\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_practice_names\u001b[39;49;00m(practice_name):\n",
      ">       \u001b[94massert\u001b[39;49;00m practice_name \u001b[95min\u001b[39;49;00m expected_practice_names\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Snake Oil Cures' in ['Northern Wellness', 'East End Doctors', 'West Park Practice', 'Southern Health']\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/tmp/ipykernel_333/1779559460.py\u001b[0m:11: AssertionError\n",
      "===================================== short test summary info ======================================\n",
      "FAILED tmpwfewm67j.py::test_practice_names[Snake Oil Cures] - AssertionError: assert 'Snake Oil C...\n",
      "\u001b[31m=================================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m4 passed\u001b[0m\u001b[31m in 0.04s\u001b[0m\u001b[31m ====================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "expected_practice_names = [\n",
    "    'Northern Wellness', \n",
    "    'East End Doctors', \n",
    "    'West Park Practice', \n",
    "    'Southern Health'\n",
    "]\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"practice_name\", df_gp_appointments[\"practice_name\"].unique())\n",
    "def test_practice_names(practice_name):\n",
    "    assert practice_name in expected_practice_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the postcodes are valid\n",
    "We can use a regex available online to check if the postcode is a valid format. There are also libraries and APIs that will check if it is a real postcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jowi60/TDD_lunch_and_learn, configfile: pytest.ini\n",
      "collected 7 items\n",
      "\n",
      "tmptpabn2kv.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                                       [100%]\u001b[0m\n",
      "\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m__________________________________ test_postcode_format[WP01 1A] ___________________________________\u001b[0m\n",
      "\n",
      "practice_post_code = 'WP01 1A'\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mpractice_post_code\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, df_gp_appointments[\u001b[33m\"\u001b[39;49;00m\u001b[33mpractice_post_code\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_postcode_format\u001b[39;49;00m(practice_post_code):\n",
      ">       \u001b[94massert\u001b[39;49;00m re.match(\n",
      "            pattern= expected_postcode_regex,\n",
      "            string= practice_post_code\n",
      "        )\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert None\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where None = <function match at 0x7fa542e6d670>(pattern='^(((([A-Z][A-Z]{0,1})[0-9][A-Z0-9]{0,1}) {0,}[0-9])[A-Z]{2})$', string='WP01 1A')\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <function match at 0x7fa542e6d670> = re.match\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/tmp/ipykernel_333/1998802357.py\u001b[0m:5: AssertionError\n",
      "===================================== short test summary info ======================================\n",
      "FAILED tmptpabn2kv.py::test_postcode_format[WP01 1A] - AssertionError: assert None\n",
      "\u001b[31m=================================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m6 passed\u001b[0m\u001b[31m in 0.06s\u001b[0m\u001b[31m ====================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "expected_postcode_regex = r'^(((([A-Z][A-Z]{0,1})[0-9][A-Z0-9]{0,1}) {0,}[0-9])[A-Z]{2})$'\n",
    "\n",
    "@pytest.mark.parametrize(\"practice_post_code\", df_gp_appointments[\"practice_post_code\"])\n",
    "def test_postcode_format(practice_post_code):\n",
    "    assert re.match(\n",
    "        pattern= expected_postcode_regex,\n",
    "        string= practice_post_code\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the dates are correct.\n",
    "The practice's should only have one submission per day. To check we can group and count submissions from each practice on each day and check there is one per practice per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /home/jowi60/TDD_lunch_and_learn, configfile: pytest.ini\n",
      "collected 6 items\n",
      "\n",
      "tmp8pbl_3wl.py \u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                                        [100%]\u001b[0m\n",
      "\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m____________________________________ test_no_repeated_dates[2] _____________________________________\u001b[0m\n",
      "\n",
      "count_of_dates = 2\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mcount_of_dates\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, df_date_count)\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_no_repeated_dates\u001b[39;49;00m(count_of_dates):\n",
      ">       \u001b[94massert\u001b[39;49;00m count_of_dates == \u001b[94m1\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 2 == 1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/tmp/ipykernel_333/2415700076.py\u001b[0m:7: AssertionError\n",
      "===================================== short test summary info ======================================\n",
      "FAILED tmp8pbl_3wl.py::test_no_repeated_dates[2] - assert 2 == 1\n",
      "\u001b[31m=================================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m5 passed\u001b[0m\u001b[31m in 0.05s\u001b[0m\u001b[31m ====================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "df_date_count = df_gp_appointments\\\n",
    "    .groupby([\"practice_name\", \"date\"])\\\n",
    "    .count()[\"practice_post_code\"]\n",
    "\n",
    "@pytest.mark.parametrize(\"count_of_dates\", df_date_count)\n",
    "def test_no_repeated_dates(count_of_dates):\n",
    "    assert count_of_dates == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of appointments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check is evil"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da06b30beef15a4b0416a58d327e74079b2e178024140331fcb6190879c218fa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pytest_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
